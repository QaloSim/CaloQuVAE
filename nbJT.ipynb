{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0e1478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[18:44:24.873]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQuVAE                                         \u001b[0mLoading configuration.\n",
      "\u001b[1m[18:44:24.876]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mWillkommen!\n",
      "\u001b[1m[18:44:24.876]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mLoading configuration.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "import hydra\n",
    "\n",
    "import wandb\n",
    "\n",
    "from data.dataManager import DataManager\n",
    "from model.modelCreator import ModelCreator\n",
    "from omegaconf import OmegaConf\n",
    "from scripts.run import setup_model, load_model_instance\n",
    "\n",
    "from utils.plots import vae_plots\n",
    "from utils.rbm_plots import plot_rbm_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e48f8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='http://127.0.0.1:8080/caloqvae/caloqvae/runs/xdkcyvtg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f36bcec2090>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"config\")\n",
    "config=compose(config_name=\"config.yaml\")\n",
    "wandb.init(tags = [config.data.dataset_name], project=config.wandb.project, entity=config.wandb.entity, config=OmegaConf.to_container(config, resolve=True), mode='offline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90abb182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[21:33:33.137]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0mKeys: ['incident_energies', 'showers']\n",
      "\u001b[1m[21:33:35.518]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0mdict_keys(['incident_energies', 'showers'])\n",
      "\u001b[1m[21:33:35.521]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f3763d742f0>: 101815 events, 796 batches\n",
      "\u001b[1m[21:33:35.522]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f36bca69a60>: 12728 events, 13 batches\n",
      "\u001b[1m[21:33:35.522]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f393e550dd0>: 12726 events, 13 batches\n",
      "\u001b[1m[21:33:35.522]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0m::Creating Model\n",
      "\u001b[1m[21:33:35.753]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "\u001b[1m[21:33:35.804]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 7 solver(s).\n",
      "\u001b[1m[21:33:36.038]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[21:33:36.087]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.4')\n",
      "\u001b[1m[21:33:36.135]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_system1.3')\n",
      "\u001b[1m[21:33:36.635]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mscripts.run                                       \u001b[0mRequesting GPUs. GPU list :[1]\n",
      "\u001b[1m[21:33:36.636]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mscripts.run                                       \u001b[0mMain GPU : cuda:1\n",
      "\u001b[1m[21:33:36.851]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mscripts.run                                       \u001b[0mCUDA available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "encoder._networks.0.seq1.0.conv.weight True\n",
      "encoder._networks.0.seq1.0.conv.bias True\n",
      "encoder._networks.0.seq1.1.weight True\n",
      "encoder._networks.0.seq1.1.bias True\n",
      "encoder._networks.0.seq1.2.weight True\n",
      "encoder._networks.0.seq1.3.conv.weight True\n",
      "encoder._networks.0.seq1.3.conv.bias True\n",
      "encoder._networks.0.seq1.4.weight True\n",
      "encoder._networks.0.seq1.4.bias True\n",
      "encoder._networks.0.seq1.5.weight True\n",
      "encoder._networks.0.seq2.0.conv.weight True\n",
      "encoder._networks.0.seq2.0.conv.bias True\n",
      "encoder._networks.0.seq2.1.weight True\n",
      "encoder._networks.0.seq2.1.bias True\n",
      "encoder._networks.0.seq2.2.weight True\n",
      "encoder._networks.0.seq2.3.conv.weight True\n",
      "encoder._networks.0.seq2.3.conv.bias True\n",
      "encoder._networks.0.seq2.4.weight True\n",
      "encoder._networks.1.seq1.0.conv.weight True\n",
      "encoder._networks.1.seq1.0.conv.bias True\n",
      "encoder._networks.1.seq1.1.weight True\n",
      "encoder._networks.1.seq1.1.bias True\n",
      "encoder._networks.1.seq1.2.weight True\n",
      "encoder._networks.1.seq1.3.conv.weight True\n",
      "encoder._networks.1.seq1.3.conv.bias True\n",
      "encoder._networks.1.seq1.4.weight True\n",
      "encoder._networks.1.seq1.4.bias True\n",
      "encoder._networks.1.seq1.5.weight True\n",
      "encoder._networks.1.seq2.0.conv.weight True\n",
      "encoder._networks.1.seq2.0.conv.bias True\n",
      "encoder._networks.1.seq2.1.weight True\n",
      "encoder._networks.1.seq2.1.bias True\n",
      "encoder._networks.1.seq2.2.weight True\n",
      "encoder._networks.1.seq2.3.conv.weight True\n",
      "encoder._networks.1.seq2.3.conv.bias True\n",
      "encoder._networks.1.seq2.4.weight True\n",
      "encoder._networks.2.seq1.0.conv.weight True\n",
      "encoder._networks.2.seq1.0.conv.bias True\n",
      "encoder._networks.2.seq1.1.weight True\n",
      "encoder._networks.2.seq1.1.bias True\n",
      "encoder._networks.2.seq1.2.weight True\n",
      "encoder._networks.2.seq1.3.conv.weight True\n",
      "encoder._networks.2.seq1.3.conv.bias True\n",
      "encoder._networks.2.seq1.4.weight True\n",
      "encoder._networks.2.seq1.4.bias True\n",
      "encoder._networks.2.seq1.5.weight True\n",
      "encoder._networks.2.seq2.0.conv.weight True\n",
      "encoder._networks.2.seq2.0.conv.bias True\n",
      "encoder._networks.2.seq2.1.weight True\n",
      "encoder._networks.2.seq2.1.bias True\n",
      "encoder._networks.2.seq2.2.weight True\n",
      "encoder._networks.2.seq2.3.conv.weight True\n",
      "encoder._networks.2.seq2.3.conv.bias True\n",
      "encoder._networks.2.seq2.4.weight True\n",
      "decoder._layers.1.conv.weight True\n",
      "decoder._layers.1.conv.bias True\n",
      "decoder._layers.2.weight True\n",
      "decoder._layers.2.bias True\n",
      "decoder._layers.3.weight True\n",
      "decoder._layers.4.conv.weight True\n",
      "decoder._layers.4.conv.bias True\n",
      "decoder._layers.5.weight True\n",
      "decoder._layers.5.bias True\n",
      "decoder._layers.6.weight True\n",
      "decoder._layers2.0.conv.weight True\n",
      "decoder._layers2.0.conv.bias True\n",
      "decoder._layers2.1.weight True\n",
      "decoder._layers2.1.bias True\n",
      "decoder._layers2.2.weight True\n",
      "decoder._layers2.3.conv.weight True\n",
      "decoder._layers2.3.conv.bias True\n",
      "decoder._layers2.4.weight True\n",
      "decoder._layers3.0.conv.weight True\n",
      "decoder._layers3.0.conv.bias True\n",
      "decoder._layers3.1.weight True\n",
      "decoder._layers3.1.bias True\n",
      "decoder._layers3.2.weight True\n",
      "decoder._layers3.3.conv.weight True\n",
      "decoder._layers3.3.conv.bias True\n",
      "decoder._layers3.4.weight True\n",
      "prior._weight_dict.01 False\n",
      "prior._weight_dict.02 False\n",
      "prior._weight_dict.03 False\n",
      "prior._weight_dict.12 False\n",
      "prior._weight_dict.13 False\n",
      "prior._weight_dict.23 False\n",
      "prior._bias_dict.0 False\n",
      "prior._bias_dict.1 False\n",
      "prior._bias_dict.2 False\n",
      "prior._bias_dict.3 False\n",
      "prior._weight_mask_dict.01 False\n",
      "prior._weight_mask_dict.02 False\n",
      "prior._weight_mask_dict.03 False\n",
      "prior._weight_mask_dict.12 False\n",
      "prior._weight_mask_dict.13 False\n",
      "prior._weight_mask_dict.23 False\n"
     ]
    }
   ],
   "source": [
    "new_model = True\n",
    "if new_model:\n",
    "    self = setup_model(config)\n",
    "    # self.model = self.model.double()  # sets all model parameters to float64\n",
    "else:\n",
    "    self = load_model_instance(config.config_path)\n",
    "    # self.model = self.model.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df06c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.evaluate(self.data_mgr.val_loader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c97187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm_hist = plot_rbm_histogram(self.RBM_energy_post, self.RBM_energy_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed19cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_plots(self.incident_energy, self.showers, self.showers_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914fabf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_tensor.py:1128: UserWarning:\n",
      "\n",
      "Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/Scalar.cpp:22.)\n",
      "\n",
      "\u001b[1m[21:44:38.315]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [0/796 (0%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 41711.0547\n",
      "\u001b[1m[21:55:59.832]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [79/796 (10%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 3001.2837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CaloQuVAE/engine/engine.py:123\u001b[39m, in \u001b[36mEngine.fit\u001b[39m\u001b[34m(self, epoch)\u001b[39m\n\u001b[32m    121\u001b[39m output = \u001b[38;5;28mself\u001b[39m.model((x, x0), \u001b[38;5;28mself\u001b[39m.beta, \u001b[38;5;28mself\u001b[39m.slope)\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m loss_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m loss_dict[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m] = torch.stack([loss_dict[key] * \u001b[38;5;28mself\u001b[39m._config.model.loss_coeff[key]  \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m loss_dict.keys() \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m != key]).sum()\n\u001b[32m    125\u001b[39m \u001b[38;5;28mself\u001b[39m.model.prior.gradient_rbm_centered(output[\u001b[32m2\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CaloQuVAE/model/autoencoder/autoencoderbase.py:112\u001b[39m, in \u001b[36mAutoEncoderBase.loss\u001b[39m\u001b[34m(self, input_data, args)\u001b[39m\n\u001b[32m    109\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    110\u001b[39m beta, post_logits, post_samples, output_activations, output_hits = args\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m kl_loss, entropy, pos_energy, neg_energy = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkl_divergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# kl_loss, entropy, pos_energy, neg_energy = 0,0,0,0\u001b[39;00m\n\u001b[32m    115\u001b[39m ae_loss = torch.pow((input_data - output_activations),\u001b[32m2\u001b[39m) * torch.exp(\u001b[38;5;28mself\u001b[39m._config.model.mse_weight*input_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CaloQuVAE/model/autoencoder/autoencoderbase.py:147\u001b[39m, in \u001b[36mAutoEncoderBase.kl_divergence\u001b[39m\u001b[34m(self, post_logits, post_samples, is_training)\u001b[39m\n\u001b[32m    143\u001b[39m pos_energy = \u001b[38;5;28mself\u001b[39m.prior.energy_exp_cond(post_samples[\u001b[32m0\u001b[39m],post_samples[\u001b[32m1\u001b[39m],post_samples[\u001b[32m2\u001b[39m],post_samples[\u001b[32m3\u001b[39m]).mean()\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# Compute gradient computation of the logZ term\u001b[39;00m\n\u001b[32m    146\u001b[39m p0_state, p1_state, p2_state, p3_state \\\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m.\u001b[49m\u001b[43mblock_gibbs_sampling_cond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpost_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpost_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpost_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# neg_energy = - self.energy_exp(p0_state, p1_state, p2_state, p3_state)\u001b[39;00m\n\u001b[32m    150\u001b[39m neg_energy = - \u001b[38;5;28mself\u001b[39m.prior.energy_exp_cond(p0_state, p1_state, p2_state, p3_state).mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CaloQuVAE/model/rbm/rbm.py:92\u001b[39m, in \u001b[36mRBM.block_gibbs_sampling_cond\u001b[39m\u001b[34m(self, p0, p1, p2, p3)\u001b[39m\n\u001b[32m     89\u001b[39m     p3 = torch.bernoulli(torch.rand(p0.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m._config.rbm.latent_nodes_per_p, device=p0.device))\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m._config.rbm.bgs_steps):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     p1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_p_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m12\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m13\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     p2 = \u001b[38;5;28mself\u001b[39m._p_state(\u001b[38;5;28mself\u001b[39m.weight_dict[\u001b[33m'\u001b[39m\u001b[33m02\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     98\u001b[39m         \u001b[38;5;28mself\u001b[39m.weight_dict[\u001b[33m'\u001b[39m\u001b[33m12\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     99\u001b[39m         \u001b[38;5;28mself\u001b[39m.weight_dict[\u001b[33m'\u001b[39m\u001b[33m23\u001b[39m\u001b[33m'\u001b[39m].T,\n\u001b[32m    100\u001b[39m         p0, p1, p3,\n\u001b[32m    101\u001b[39m         \u001b[38;5;28mself\u001b[39m.bias_dict[\u001b[33m'\u001b[39m\u001b[33m2\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    102\u001b[39m     p3 = \u001b[38;5;28mself\u001b[39m._p_state(\u001b[38;5;28mself\u001b[39m.weight_dict[\u001b[33m'\u001b[39m\u001b[33m03\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    103\u001b[39m         \u001b[38;5;28mself\u001b[39m.weight_dict[\u001b[33m'\u001b[39m\u001b[33m13\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    104\u001b[39m         \u001b[38;5;28mself\u001b[39m.weight_dict[\u001b[33m'\u001b[39m\u001b[33m23\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    105\u001b[39m         p0, p1, p2,\n\u001b[32m    106\u001b[39m         \u001b[38;5;28mself\u001b[39m.bias_dict[\u001b[33m'\u001b[39m\u001b[33m3\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CaloQuVAE/model/rbm/rbm.py:35\u001b[39m, in \u001b[36mRBM._p_state\u001b[39m\u001b[34m(self, weights_ax, weights_bx, weights_cx, pa_state, pb_state, pc_state, bias_x)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"partition_state()\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[33;03m:param weights_a (torch.Tensor) : (n_nodes_a, n_nodes_x)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33;03m:param bias_x (torch.Tensor) : (n_nodes_x)\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     32\u001b[39m p_activations = (torch.matmul(pa_state, weights_ax) +\n\u001b[32m     33\u001b[39m                  torch.matmul(pb_state, weights_bx) +\n\u001b[32m     34\u001b[39m                  torch.matmul(pc_state, weights_cx) + bias_x)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.bernoulli(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_activations\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "self.fit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f74306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
