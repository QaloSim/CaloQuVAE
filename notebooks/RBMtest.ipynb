{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83206f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[22:00:23.197]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQuVAE                                         \u001b[0mLoading configuration.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "import hydra\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import copy\n",
    "\n",
    "from model.rbm.rbm import RBM\n",
    "from model.rbm.rbm_torch import RBMtorch\n",
    "from scripts.run import setup_model, load_model_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3254aaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/niiwyndu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7b509a6510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"config\")\n",
    "cfg=compose(config_name=\"config.yaml\")\n",
    "wandb.init(tags = [cfg.data.dataset_name], project=cfg.wandb.project, entity=cfg.wandb.entity, config=OmegaConf.to_container(cfg, resolve=True), mode='disabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e38c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[22:00:28.236]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0mLoading ATLAS dataset: AtlasReg035\n",
      "\u001b[1m[22:00:30.502]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f7b5128bd70>: 101815 events, 398 batches\n",
      "\u001b[1m[22:00:30.505]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f7b5132e570>: 12728 events, 13 batches\n",
      "\u001b[1m[22:00:30.505]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f7b51e39df0>: 12726 events, 13 batches\n",
      "\u001b[1m[22:00:30.506]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0m::Creating Model\n",
      "\u001b[1m[22:00:31.153]\u001b[0m \u001b[1;93mWARN \u001b[1;0m  \u001b[1mmodel.rbm.zephyr                                  \u001b[0mQPU is offline. Setting a hard-coded zephyr. Check to see you're pinging the correct chip_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leozhu/CaloQuVAE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[22:00:33.211]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mscripts.run                                       \u001b[0mRequesting GPUs. GPU list :[5]\n",
      "\u001b[1m[22:00:33.212]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mscripts.run                                       \u001b[0mMain GPU : cuda:5\n",
      "\u001b[1m[22:00:33.400]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mscripts.run                                       \u001b[0mCUDA available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n",
      "encoder._networks.0.seq1.0.conv.weight True\n",
      "encoder._networks.0.seq1.0.conv.bias True\n",
      "encoder._networks.0.seq1.1.weight True\n",
      "encoder._networks.0.seq1.1.bias True\n",
      "encoder._networks.0.seq1.2.weight True\n",
      "encoder._networks.0.seq1.3.conv.weight True\n",
      "encoder._networks.0.seq1.3.conv.bias True\n",
      "encoder._networks.0.seq1.4.weight True\n",
      "encoder._networks.0.seq1.4.bias True\n",
      "encoder._networks.0.seq1.5.weight True\n",
      "encoder._networks.0.seq2.0.conv.weight True\n",
      "encoder._networks.0.seq2.0.conv.bias True\n",
      "encoder._networks.0.seq2.1.weight True\n",
      "encoder._networks.0.seq2.1.bias True\n",
      "encoder._networks.0.seq2.2.weight True\n",
      "encoder._networks.0.seq2.3.conv.weight True\n",
      "encoder._networks.0.seq2.3.conv.bias True\n",
      "encoder._networks.0.seq2.4.weight True\n",
      "encoder._networks.1.seq1.0.conv.weight True\n",
      "encoder._networks.1.seq1.0.conv.bias True\n",
      "encoder._networks.1.seq1.1.weight True\n",
      "encoder._networks.1.seq1.1.bias True\n",
      "encoder._networks.1.seq1.2.weight True\n",
      "encoder._networks.1.seq1.3.conv.weight True\n",
      "encoder._networks.1.seq1.3.conv.bias True\n",
      "encoder._networks.1.seq1.4.weight True\n",
      "encoder._networks.1.seq1.4.bias True\n",
      "encoder._networks.1.seq1.5.weight True\n",
      "encoder._networks.1.seq2.0.conv.weight True\n",
      "encoder._networks.1.seq2.0.conv.bias True\n",
      "encoder._networks.1.seq2.1.weight True\n",
      "encoder._networks.1.seq2.1.bias True\n",
      "encoder._networks.1.seq2.2.weight True\n",
      "encoder._networks.1.seq2.3.conv.weight True\n",
      "encoder._networks.1.seq2.3.conv.bias True\n",
      "encoder._networks.1.seq2.4.weight True\n",
      "encoder._networks.2.seq1.0.conv.weight True\n",
      "encoder._networks.2.seq1.0.conv.bias True\n",
      "encoder._networks.2.seq1.1.weight True\n",
      "encoder._networks.2.seq1.1.bias True\n",
      "encoder._networks.2.seq1.2.weight True\n",
      "encoder._networks.2.seq1.3.conv.weight True\n",
      "encoder._networks.2.seq1.3.conv.bias True\n",
      "encoder._networks.2.seq1.4.weight True\n",
      "encoder._networks.2.seq1.4.bias True\n",
      "encoder._networks.2.seq1.5.weight True\n",
      "encoder._networks.2.seq2.0.conv.weight True\n",
      "encoder._networks.2.seq2.0.conv.bias True\n",
      "encoder._networks.2.seq2.1.weight True\n",
      "encoder._networks.2.seq2.1.bias True\n",
      "encoder._networks.2.seq2.2.weight True\n",
      "encoder._networks.2.seq2.3.conv.weight True\n",
      "encoder._networks.2.seq2.3.conv.bias True\n",
      "encoder._networks.2.seq2.4.weight True\n",
      "decoder.subdecoders.0._layers1.0.conv.weight True\n",
      "decoder.subdecoders.0._layers1.0.conv.bias True\n",
      "decoder.subdecoders.0._layers1.1.weight True\n",
      "decoder.subdecoders.0._layers1.1.bias True\n",
      "decoder.subdecoders.0._layers1.2.weight True\n",
      "decoder.subdecoders.0._layers1.3.conv.weight True\n",
      "decoder.subdecoders.0._layers1.3.conv.bias True\n",
      "decoder.subdecoders.0._layers1.4.weight True\n",
      "decoder.subdecoders.0._layers1.4.bias True\n",
      "decoder.subdecoders.0._layers1.5.weight True\n",
      "decoder.subdecoders.0._layers1.6.conv.weight True\n",
      "decoder.subdecoders.0._layers1.6.conv.bias True\n",
      "decoder.subdecoders.0._layers1.7.weight True\n",
      "decoder.subdecoders.0._layers1.7.bias True\n",
      "decoder.subdecoders.0._layers1.8.weight True\n",
      "decoder.subdecoders.0._layers2.0.weight True\n",
      "decoder.subdecoders.0._layers2.0.bias True\n",
      "decoder.subdecoders.0._layers2.1.weight True\n",
      "decoder.subdecoders.0._layers2.1.bias True\n",
      "decoder.subdecoders.0._layers2.3.to_qkv.weight True\n",
      "decoder.subdecoders.0._layers2.3.to_out.0.weight True\n",
      "decoder.subdecoders.0._layers2.3.to_out.0.bias True\n",
      "decoder.subdecoders.0._layers2.3.to_out.1.weight True\n",
      "decoder.subdecoders.0._layers2.3.to_out.1.bias True\n",
      "decoder.subdecoders.0._layers2.4.weight True\n",
      "decoder.subdecoders.0._layers2.4.bias True\n",
      "decoder.subdecoders.0._layers2.5.weight True\n",
      "decoder.subdecoders.0._layers2.5.bias True\n",
      "decoder.subdecoders.0._layers2.7.to_qkv.weight True\n",
      "decoder.subdecoders.0._layers2.7.to_out.0.weight True\n",
      "decoder.subdecoders.0._layers2.7.to_out.0.bias True\n",
      "decoder.subdecoders.0._layers2.7.to_out.1.weight True\n",
      "decoder.subdecoders.0._layers2.7.to_out.1.bias True\n",
      "decoder.subdecoders.0._layers2_hits.0.weight True\n",
      "decoder.subdecoders.0._layers2_hits.0.bias True\n",
      "decoder.subdecoders.0._layers2_hits.1.weight True\n",
      "decoder.subdecoders.0._layers2_hits.1.bias True\n",
      "decoder.subdecoders.0._layers2_hits.2.weight True\n",
      "decoder.subdecoders.0._layers2_hits.3.weight True\n",
      "decoder.subdecoders.0._layers2_hits.3.bias True\n",
      "decoder.subdecoders.0._layers2_hits.4.weight True\n",
      "decoder.subdecoders.0._layers2_hits.4.bias True\n",
      "decoder.subdecoders.0._layers2_hits.5.weight True\n",
      "decoder.subdecoders.0._layers2_hits.6.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.0.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.0.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.1.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.1.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.3.to_qkv.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.3.to_out.0.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.3.to_out.0.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.3.to_out.1.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.3.to_out.1.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.4.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.4.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.5.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.5.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.7.to_qkv.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.7.to_out.0.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.7.to_out.0.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.7.to_out.1.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.7.to_out.1.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.8.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.8.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.9.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.9.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.11.to_qkv.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.11.to_out.0.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.11.to_out.0.bias True\n",
      "decoder.subdecoders.1._subdecoder_layers.11.to_out.1.weight True\n",
      "decoder.subdecoders.1._subdecoder_layers.11.to_out.1.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.0.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.0.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.1.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.1.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.3.to_qkv.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.3.to_out.0.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.3.to_out.0.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.3.to_out.1.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.3.to_out.1.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.4.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.4.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.5.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.5.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.7.to_qkv.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.7.to_out.0.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.7.to_out.0.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.7.to_out.1.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.7.to_out.1.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.8.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.8.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.9.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.9.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.11.to_qkv.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.11.to_out.0.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.11.to_out.0.bias True\n",
      "decoder.subdecoders.2._subdecoder_layers.11.to_out.1.weight True\n",
      "decoder.subdecoders.2._subdecoder_layers.11.to_out.1.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.0.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.0.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.1.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.1.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.3.to_qkv.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.3.to_out.0.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.3.to_out.0.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.3.to_out.1.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.3.to_out.1.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.4.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.4.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.5.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.5.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.7.to_qkv.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.7.to_out.0.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.7.to_out.0.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.7.to_out.1.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.7.to_out.1.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.8.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.8.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.9.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.9.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.11.to_qkv.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.11.to_out.0.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.11.to_out.0.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.11.to_out.1.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.11.to_out.1.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.12.weight True\n",
      "decoder.subdecoders.3._subdecoder_layers.12.bias True\n",
      "decoder.subdecoders.3._subdecoder_layers.13.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.0.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.0.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.1.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.1.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.2.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.3.to_qkv.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.3.to_out.0.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.3.to_out.0.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.3.to_out.1.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.3.to_out.1.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.4.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.4.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.5.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.5.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.6.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.7.to_qkv.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.7.to_out.0.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.7.to_out.0.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.7.to_out.1.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.7.to_out.1.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.8.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.8.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.9.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.9.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.10.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.11.to_qkv.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.11.to_out.0.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.11.to_out.0.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.11.to_out.1.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.11.to_out.1.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.12.weight True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.12.bias True\n",
      "decoder.subdecoders.3._last_subdecoder_hits.13.weight True\n",
      "decoder.skip_connections.0.0.weight True\n",
      "decoder.skip_connections.0.0.bias True\n",
      "decoder.skip_connections.0.1.weight True\n",
      "decoder.skip_connections.0.1.bias True\n",
      "decoder.skip_connections.0.2.weight True\n",
      "decoder.skip_connections.0.3.weight True\n",
      "decoder.skip_connections.0.3.bias True\n",
      "decoder.skip_connections.0.4.weight True\n",
      "decoder.skip_connections.0.4.bias True\n",
      "decoder.skip_connections.0.5.weight True\n",
      "decoder.skip_connections.0.6.weight True\n",
      "decoder.skip_connections.0.6.bias True\n",
      "decoder.skip_connections.1.0.weight True\n",
      "decoder.skip_connections.1.0.bias True\n",
      "decoder.skip_connections.1.1.weight True\n",
      "decoder.skip_connections.1.1.bias True\n",
      "decoder.skip_connections.1.2.weight True\n",
      "decoder.skip_connections.1.3.weight True\n",
      "decoder.skip_connections.1.3.bias True\n",
      "decoder.skip_connections.1.4.weight True\n",
      "decoder.skip_connections.1.4.bias True\n",
      "decoder.skip_connections.1.5.weight True\n",
      "decoder.skip_connections.1.6.weight True\n",
      "decoder.skip_connections.1.6.bias True\n",
      "decoder.skip_connections.2.0.weight True\n",
      "decoder.skip_connections.2.0.bias True\n",
      "decoder.skip_connections.2.1.weight True\n",
      "decoder.skip_connections.2.1.bias True\n",
      "decoder.skip_connections.2.2.weight True\n",
      "decoder.skip_connections.2.3.weight True\n",
      "decoder.skip_connections.2.3.bias True\n",
      "decoder.skip_connections.2.4.weight True\n",
      "decoder.skip_connections.2.4.bias True\n",
      "decoder.skip_connections.2.5.weight True\n",
      "decoder.skip_connections.2.6.weight True\n",
      "decoder.skip_connections.2.6.bias True\n",
      "prior._weight_dict.01 False\n",
      "prior._weight_dict.02 False\n",
      "prior._weight_dict.03 False\n",
      "prior._weight_dict.12 False\n",
      "prior._weight_dict.13 False\n",
      "prior._weight_dict.23 False\n",
      "prior._bias_dict.0 False\n",
      "prior._bias_dict.1 False\n",
      "prior._bias_dict.2 False\n",
      "prior._bias_dict.3 False\n",
      "prior._weight_mask_dict.01 False\n",
      "prior._weight_mask_dict.02 False\n",
      "prior._weight_mask_dict.03 False\n",
      "prior._weight_mask_dict.12 False\n",
      "prior._weight_mask_dict.13 False\n",
      "prior._weight_mask_dict.23 False\n"
     ]
    }
   ],
   "source": [
    "#config.wandb.watch = 0\n",
    "new_model = True\n",
    "if new_model:\n",
    "    self = setup_model(cfg)\n",
    "else:\n",
    "    config = OmegaConf.load(cfg.config_path)\n",
    "    config.gpu_list = cfg.gpu_list\n",
    "    config.load_state = cfg.load_state\n",
    "    self = setup_model(config)\n",
    "    self._model_creator.load_state(config.run_path, self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48600a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_tensor.py:1128: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/Scalar.cpp:22.)\n",
      "  return self.item().__format__(format_spec)\n",
      "\u001b[1m[22:00:40.689]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [0/398 (0%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 53472.2188\n",
      "\u001b[1m[22:02:07.635]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [39/398 (10%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 1852.2350\n",
      "\u001b[1m[22:03:39.855]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [78/398 (20%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 1328.2241\n",
      "\u001b[1m[22:05:14.077]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [117/398 (29%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 1112.7279\n",
      "\u001b[1m[22:06:47.109]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [156/398 (39%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 737.5708\n",
      "\u001b[1m[22:08:16.929]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [195/398 (49%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 753.9871\n",
      "\u001b[1m[22:09:43.202]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [234/398 (59%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 695.3203\n",
      "\u001b[1m[22:11:09.445]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [273/398 (69%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 609.4010\n",
      "\u001b[1m[22:12:35.731]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [312/398 (78%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 604.4841\n",
      "\u001b[1m[22:14:02.233]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [351/398 (88%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 605.3434\n",
      "\u001b[1m[22:15:31.772]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mEpoch: 0 [390/398 (98%)]\t beta: 1.000, slope: 0.050 \t Batch Loss: 618.2986\n",
      "\u001b[1m[22:15:47.348]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0mUsing WandB run directory: /tmp\n",
      "\u001b[1m[22:15:47.351]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0mSaving model state to /tmp/autoencoderbase_0.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/autoencoderbase_0_config.yaml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)\n",
    "self.fit_vae(0)\n",
    "self._save_model(name=str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f1cb147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[22:22:36.316]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0mLoading state\n",
      "\u001b[1m[22:22:36.598]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0mLoading weights from file : /tmp/autoencoderbase_0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for module =  _hit_smoothing_dist_mod\n",
      "Loading weights for module =  _bce_loss\n",
      "Loading weights for module =  encoder\n",
      "Loading weights for module =  decoder\n",
      "Loading weights for module =  prior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[22:22:37.051]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0mLoaded VAE optimizer state\n",
      "\u001b[1m[22:22:37.063]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodel.modelCreator                                \u001b[0mLoaded RBM optimizer state\n"
     ]
    }
   ],
   "source": [
    "self.model_creator.load_state(\"/tmp/autoencoderbase_0.pth\", self.device, self.optimiser, self.model.prior.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "manual_RBM = RBM(config)\n",
    "manual_weights = manual_RBM.weight_dict\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch_RBM = RBMtorch(config)\n",
    "torch_weights = torch_RBM.weight_dict\n",
    "\n",
    "#check if two weight dicts are equal\n",
    "assert manual_weights.keys() == torch_weights.keys()\n",
    "for key in manual_weights.keys():\n",
    "    assert torch.all(manual_weights[key] == torch_weights[key])\n",
    "# print top values in both weight dicts\n",
    "# print(\"Manual RBM weights:\")\n",
    "# print(manual_weights['02'][0])\n",
    "# print(\"Torch RBM weights:\")\n",
    "# print(torch_weights['02'][0])\n",
    "\n",
    "# calculate mock gradients\n",
    "# manual_RBM.calculate_mock_gradient()\n",
    "# torch_RBM.calculate_mock_gradient()\n",
    "\n",
    "#generate dummy post_samples\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_samples = 10\n",
    "n_nodes_p = config.rbm.latent_nodes_per_p\n",
    "post_samples = [\n",
    "    torch.randint(0, 2, (n_samples, n_nodes_p), dtype=torch.float32)\n",
    "    for _ in range(4)\n",
    "]\n",
    "\n",
    "# Compute gradients with identical RNG sequences\n",
    "with torch.random.fork_rng():\n",
    "    torch.manual_seed(123)\n",
    "    manual_RBM.gradient_rbm_centered(post_samples)\n",
    "\n",
    "with torch.random.fork_rng():\n",
    "    torch.manual_seed(123)\n",
    "    torch_RBM.gradient_rbm_centered(post_samples)\n",
    "\n",
    "# Compare with tolerances + diagnostics\n",
    "for kind in (\"bias\", \"weight\"):\n",
    "    for key in manual_RBM.grad[kind]:\n",
    "        a = manual_RBM.grad[kind][key]\n",
    "        b = torch_RBM.grad[kind][key]\n",
    "        if not torch.allclose(a, b, rtol=1e-5, atol=1e-8):\n",
    "            diff = (a - b).abs().max().item()\n",
    "            print(f\"{kind}.{key} differ, max|Î”|={diff}\")\n",
    "\n",
    "# use different optimizers\n",
    "manual_RBM.initOpt()\n",
    "manual_RBM.update_params()\n",
    "\n",
    "torch_RBM.initOpt_torch()\n",
    "torch_RBM.update_params_torch()\n",
    "\n",
    "# print top values in both weight dicts\n",
    "manual_weights = manual_RBM._weight_dict\n",
    "torch_weights = torch_RBM.weight_dict\n",
    "print(\"Manual RBM weights:\")\n",
    "print(manual_weights['02'][0])\n",
    "print(\"Torch RBM weights:\")\n",
    "print(torch_weights['02'][0])\n",
    "\n",
    "for i, group in enumerate(torch_RBM.opt.param_groups):\n",
    "    print(f\"Param group {i}\")\n",
    "    for p in group['params']:\n",
    "        print(\"  id:\", id(p), \" shape:\", p.shape, \" requires_grad:\", p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "# check if weights are equal\n",
    "assert manual_weights.keys() == torch_weights.keys()\n",
    "for key in manual_weights.keys():\n",
    "    diff = (manual_weights[key] - torch_weights[key]).abs().max()\n",
    "    print(f\"Max diff for {key}: {diff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "rbm_torch = RBMtorch(config)\n",
    "# Clone weights before update\n",
    "before_update = {k: v.clone() for k, v in rbm_torch._weight_dict.items()}\n",
    "\n",
    "# before step\n",
    "p = rbm_torch._weight_dict['01']\n",
    "print(id(p), p.storage().data_ptr())\n",
    "\n",
    "\n",
    "# Perform optimizer step\n",
    "rbm_torch.initOpt_torch()\n",
    "rbm_torch.calculate_mock_gradient()\n",
    "rbm_torch.update_params_torch()\n",
    "\n",
    "\n",
    "rbm_torch.update_params_torch()\n",
    "\n",
    "# Clone weights after update\n",
    "after_update = {k: v.clone() for k, v in rbm_torch._weight_dict.items()}\n",
    "# after step: these must be identical\n",
    "q = rbm_torch._weight_dict['01']\n",
    "print(id(q), q.storage().data_ptr())\n",
    "\n",
    "# Check for changes\n",
    "for k in before_update:\n",
    "    changed = not torch.allclose(before_update[k], after_update[k])\n",
    "    print(f\"Weights for '{k}' updated: {changed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e69243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testRBM(RBM):\n",
    "    def calculate_mock_gradient(self):\n",
    "        \"\"\"Creates a deterministic mock gradient for testing.\"\"\"\n",
    "        self.grad = {\"bias\": {}, \"weight\": {}}\n",
    "        for key, param in self.bias_dict.items():\n",
    "            self.grad[\"bias\"][key] = torch.ones_like(param) * 0.1\n",
    "        for key, param in self.weight_dict.items():\n",
    "            self.grad[\"weight\"][key] = torch.ones_like(param) * -0.05\n",
    "RBMinitial = testRBM(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_custom = copy.deepcopy(RBMinitial)\n",
    "rbm_custom.initOpt()\n",
    "rbm_custom.calculate_mock_gradient()\n",
    "\n",
    "initial_weight_01 = rbm_custom.weight_dict['01'].data.clone()\n",
    "rbm_custom.update_params()\n",
    "final_weight_custom = rbm_custom.weight_dict['01'].data.clone()\n",
    "\n",
    "print(f\"Initial Weight (Top 5 values): {initial_weight_01.flatten()[:5].tolist()}\")\n",
    "print(f\"Final Weight (Top 5 values):   {final_weight_custom.flatten()[:5].tolist()}\\n\")\n",
    "\n",
    "rbm_torch = copy.deepcopy(RBMinitial)\n",
    "rbm_torch.initOpt_torch()\n",
    "rbm_torch.calculate_mock_gradient()\n",
    "\n",
    "initial_weight_01_torch = rbm_torch.weight_dict['01'].data.clone()\n",
    "rbm_torch.update_params_torch()\n",
    "final_weight_torch = rbm_torch.weight_dict['01'].data.clone()\n",
    "\n",
    "print(f\"Initial Weight (Top 5 values): {initial_weight_01_torch.flatten()[:5].tolist()}\")\n",
    "print(f\"Final Weight (Top 5 values):   {final_weight_torch.flatten()[:5].tolist()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Running Test 1: Custom AdamOpt (Adam with L2 Regularization) ---\")\n",
    "rbm_custom = copy.deepcopy(rbm_initial)\n",
    "rbm_custom.initOpt()\n",
    "rbm_custom.calculate_mock_gradient()\n",
    "\n",
    "# Store initial weights for comparison\n",
    "initial_weight_01 = rbm_custom.weight_dict['01'].data.clone()\n",
    "rbm_custom.update_params()\n",
    "final_weight_custom = rbm_custom.weight_dict['01'].data.clone()\n",
    "\n",
    "print(f\"Initial Weight (Top 5 values): {initial_weight_01.flatten()[:5].tolist()}\")\n",
    "print(f\"Final Weight (Top 5 values):   {final_weight_custom.flatten()[:5].tolist()}\\n\")\n",
    "\n",
    "\n",
    "# --- Test 2: PyTorch's Adam (AdamW) Implementation ---\n",
    "print(\"--- Running Test 2: PyTorch `torch.optim.Adam` (AdamW) ---\")\n",
    "rbm_torch = copy.deepcopy(rbm_initial)\n",
    "rbm_torch.initOpt_torch()\n",
    "rbm_torch.calculate_mock_gradient()\n",
    "\n",
    "# Store initial weights (should be identical to the other test)\n",
    "initial_weight_01_torch = rbm_torch.weight_dict['01'].data.clone()\n",
    "rbm_torch.update_params_torch()\n",
    "final_weight_torch = rbm_torch.weight_dict['01'].data.clone()\n",
    "\n",
    "print(f\"Initial Weight (Top 5 values): {initial_weight_01_torch.flatten()[:5].tolist()}\")\n",
    "print(f\"Final Weight (Top 5 values):   {final_weight_torch.flatten()[:5].tolist()}\\n\")\n",
    "\n",
    "# --- Comparison and Conclusion ---\n",
    "print(\"--- Comparison ---\")\n",
    "# Check if initial weights are identical\n",
    "are_initial_weights_same = torch.allclose(initial_weight_01, initial_weight_01_torch)\n",
    "print(f\"Initial weights were identical: {are_initial_weights_same}\")\n",
    "\n",
    "# Check if final weights are identical\n",
    "are_final_weights_same = torch.allclose(final_weight_custom, final_weight_torch)\n",
    "print(f\"Final weights are identical: {are_final_weights_same}\")\n",
    "\n",
    "if not are_final_weights_same:\n",
    "    difference = torch.mean(torch.abs(final_weight_custom - final_weight_torch))\n",
    "    print(f\"Average absolute difference between final weights: {difference.item():.8f}\")\n",
    "    print(\"\\nConclusion: The final weights are different, confirming the optimizer behaviors are not identical.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
